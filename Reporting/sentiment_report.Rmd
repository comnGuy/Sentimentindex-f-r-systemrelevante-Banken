---
#title: "Sentimentindex f?r systemrelevate Banke"
output: pdf_document
---

---
classoption: oneside
documentclass: article
fontsize: 12pt
header-includes:
- \usepackage{amsthm}
- \usepackage{xcolor}
- \usepackage[ngerman]{babel}
- \usepackage[utf8]{inputenc}
- \usepackage{amsmath}
- \usepackage{amsfonts}
- \usepackage{amssymb}
- \usepackage[mathscr]{euscript}
- \usepackage{graphicx}
- \usepackage{subcaption}
- \usepackage{tabularx}
- \usepackage{url}
- \usepackage{hyperref}
- \usepackage[]{algorithm2e}
- \usepackage{mdframed}
- \usepackage{lipsum}
- \usepackage{extarrows}
- \usepackage[most]{tcolorbox}
- \usepackage{color}
- \usepackage{paralist}
- \usepackage{amsthm}
- \usepackage{blindtext}
- \usepackage{fancyhdr}
- \usepackage{colortbl}
- \usepackage{framed}
- \usepackage{float}
- \usepackage{listings}
- \usepackage{fancyhdr}

output:
  pdf_document:
    number_sections: yes
  html_document: default
---
```{r, echo=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.align="center")
```




\newcommand{\mybox}[1]{%
  \tikz[baseline=(text.base)]
    {\node [draw,rounded corners,fill=red!20] (text) {#1};}%
}

\newtheoremstyle{normal}
{10pt} 
{10pt}
{\normalfont}
{}
{\bfseries}
{}
{0.8em}
{\bfseries{\thmname{#1} \thmnumber{#2}\thmnote{ \hspace{0.5em}(#3)\newline}}}
\theoremstyle{normal}

\newtheorem{satz}{Satz}
\newtheorem{defin}{Definition}
\newtheorem{beispiel}{Beispiel}


\pagenumbering{roman}

\renewcommand{\headrulewidth}{0.5pt}
\lhead{\nouppercase{\rightmark}}\rhead{}
<!-- \renewcommand{\sectionmark}[1]{\markright{\thesection.\ #1}} -->
<!-- \onehalfspacing -->
<!-- \cleardoublepage -->


\numberwithin{equation}{section}
\numberwithin{figure}{section}


\setlength{\parindent}{0pt} 
\renewcommand{\footrulewidth}{1pt}
\pagenumbering{arabic}

<!--- Titelseite ---> \input{Titelblatt2}
<!--- Inhaltsverzeichnis ---> \tableofcontents\newpage
<!--- Abbildungsverzeichnis ---> \listoffigures\newpage

\newcommand*{\secref}[1]{Section~\ref{#1}}

<!--- Beginn --->
\section{Ergebnisse} 

<!-- In einem Paper vom Herrn Becker stand, dass das Ergebnis direkt zu Begin prC$sentiert werden sollte -->


\section{Einf?hrung}

<!-- Sachen wir wir evtl. benC6tigen, oder soll das weggelassen werden? -->
\section{Aufgabenbeschreibung} 
Eine Sentiment Analyse soll ?ber die zehn g?r?ten Bank mittels den Twitterdaten auf Cuda erstellt werden. Die Twitterdaten liegen als R-Dataframe vor. Die Tabelle zeigt den Aufbau des DataFrames und die benC6tigten Daten. 

\begin{table}[H]
  \centering
  \begin{tabular}{lrrrr}
	Tweets & Follower			& favourites\_count			& friends\_count			& ... \\
    \hline
    My twit pic is sexy	& 81	& 101	& 3523	& 85 \\
    I am I really this tired	& 233	& 517	& 23542	& 99 \\
    F5 Copy	& 181	& 345	& 2672	& 99 \\
  \end{tabular}
  \caption{Ein Ausschnitt des DataFrames vom Cuda} \label{tab:example_dataframe_twits}
\end{table}


<!-- Wo kommen die Daten her? Welches Format hatten die Daten? Welches Format benutzen wird? -->
\section{Daten}
Um ein Sentiment zu bilden, werden Daten mit Texten von Nutzern benötigt. Diese Daten wurden aus den zwei Quellen des Twitterarchives und durch die Twitter-API bezogen.
Weiterhin wurden Daten für den Vergleich mit den Sentiments benötigt, hier im Unterkapitel Dividende (TODO) zu finden.
\subsection{Twitterarchive}
Twitter veröffentlicht monatlich 1 % ihrer gesamten Tweets. Auf dem CUDA-Rechner wurde das Twitterarchive aus dem Jahr 2012 in einem R-spezifischen DataFrame aufbereitet und zur Verfügung gestellt. Da diese Twitterdaten alle Tweets enthalten, auch Tweets die nicht benötigt werden, wurde ein Filter gebaut, der die benötigten Daten filtert.

![Filter für grieschiche Banken \label{fig:filter}](Pictures/filter_twitter_archive.PNG)

In der Abbildung \ref{fig:filter} ist ein Filter für die grieschichen Banken zu sehen. Die Begriffe, nachdem gefilter wird, sind in grün zu sehen. Diese sind jeweils durch einem logischen "Oder" getrennt. Wird ein Begriff in einem Tweet gefunden, wurde dieser Tweet in unserem Datenbestand mitaufgenommen. 

Eine große Herausforderung war das Finden sinnvoller Begriffe zum Filtern. Sind die Begriffe nicht wohlwollend gewählt, könnten folgende Fälle eintreten, die sich wiederum negativ auf dem Sentiment auswirken könnten.

 * Ist ein Begriff zu allgemein gewählt, besteht die Möglichkeit Überschneidungen mit weiteren nicht bezogenen Themen auszuwählen. Z.B. ist der Begriff \textit{Bank} zu allgemein gewählt, da die Bank im Park oder die Bank im Glücksspiel gemeint sein könnte. An dieser Stelle kann die Anzahl der nicht gewollten Tweets abgewägt werden. Sind diese anteilig gering, kann es Sinn ergeben den Begriff als Filter aufzunehmen.
 * Ist ein Begriff zu speziell gewählt, besteht die Möglichkeit zu wenige Tweets mit einzubeziehen.

Die Wahl der Begriffe ist demnach ein Trade-Off zwischen der Noise, die Anzahl der nicht relevanten Themen, und die Anzahl der gesamten Tweets, die nach dem Filtern übrig bleibt. Werden die Begriffe zu allgemein gewählt, werden zwar viele Tweets einbezogen, jedoch wird die Noise sehr hoch. Werden die Filter zu streng gewählt, besteht die Möglichkeit zu wenige Tweets nach dem Filtern einzubeziehen.

Insgesamt wurden ca. 17.000 Tweets durch die gewählten Filter über das gesamte Jahre 2012 gefiltert. Da das Sentiment wöchentlich gebildet wird, sind das ca. 325 Tweets pro Woche, die für das Bilden eines Sentiments ausreichen.

\subsection{Twitter-API}
\label{sub:scanned_data}
Zu Beginn war nicht klar, ob ausreichend Daten durch das Twitterarchive gewonnen werden können. Dadurch ergab sich die Idee, die Twitter-API zusätzlich zu verwenden. Die Twitter-API erlaubt 450 Anfragen alle 15 Minuten. Der Kern des PHP-Skriptes wird durch folgenden Code erleutert.

```php
// Query with one Hashtag and a limit up to 100
// GET call
$getfield = '?q=' . $hastag . '&
              result_type=recent&
              count=100&
              tweet_mode=extended';

// Setting up the Twitter-API
$twitter = new TwitterAPIExchange($this->settings);

// Perform the request
$data = $twitter->setGetfield($getfield)
		            ->buildOauth($this->url, $this->requestMethod)
		            ->performRequest();
```
Der obige Code zeigt die Abfrage eines Hastags. Die verschiedenen Hashtags werden mittels einer Schleife iteriert. Der Abruf (GET) wird mit einem URL Aufruf realisiert. Hierbei können verschiedene Einstellungen, wie Anzahl der maximalen Tweets (\textit{100}), welcher Typ (\textit{recent}) und in welchen Mode (\textit{extended}) werden die Tweets zurück gegeben. Als nächstes werden die Settings übergeben. Die Settings \textit{oauth\_access\_token}, \textit{oauth\_access\_token\_secret}, textit{consumer\_key} und \textit{consumer\_secret} werden durch Twitter generiert. Danach wird die Abfrage mittels der Twitter-Klasse realisiert. Als Rückgabe erhält man einen Array im JSON-Format mit den letzten 100 Tweets. Zum Speichern werden die Tweets aufbereitet und als JSON-Format gespeichert.

Der aktuelle Stand des Skriptes ist, dass es zum Ausführen manuel angestoßen werden muss. Dieses Problem wird durch ein \textit{Cronjob} gelöst. Ein Cronjob ist im Stande in definierten Intervallen oder an definierten Zeitpunkten ein Event, in unserem Fall eine PHP-Datei, auszuführen. An dieser Stelle wurde entschieden, dass höher frequentierte Tweets auf einem zwei Minuten Intervall und weniger frequentierte Tweets auf einem 15 Minuten Intervall gestellt werden.

\subsection{Dividende}
\label{sub:dividende}
TODO



\section{Wörterbücher}
Bevor ein Sentimentindex über ein Tweet erstellt werden kann, müssen die Stimmungen aus dem jeweiligen Tweet extrahiert werden. Diese Extraktion passiert im einfachsten Fall mit einem oder mehreren Wörterbüchern.

Der Aufbau eines Wörterbuches ist häufig ähnlich, wobei die Wörter in einer Liste aufgelistet und bewertet werden. Die Bewertung kann 1/0, Negativ/Positive, 0-10 usw. sein. Die Abbildung \ref{fig:worterbuch} zeigt ein Wörterbuch aus dem R-Package "tidytext". Die Spalte "word" steht für das bewertende Wort und "sentiment" für deren Bewertung.

![Positiv/Negativ Wörterbuch \label{fig:worterbuch}](Pictures/worterbuch.PNG)

\textbf{Hononym} ist der Begriff für die Doppeldeutigkeit eines Wortes, zum Beispiel "Bank". Wird ein Wort für ein Wörterbuch bewertet, muss der Kontext in dem sich das Wörterbuch befindet, beachtet werden. Angenommen es steht jeweils ein Wörterbuch für die Natur und dem Immobiliensektor zur Verfügung. Das Wort "Bank" kann in diesem Fall zwei unterschiedliche Bewertung erhalten. In der Natur könnte eine Bank eher als positiv bewertet werden, wohingegen die Bank für den Immobiliensektor eher negativ ausgelegt werden könnte.

Um die \textbf{Güte eines Wörterbuches} beurteilen zu können, werden Tweets benötigt, die in irgendeiner Art und Weise eine Bewertung beinhalten. Der gegebene Datensatz aus Kapitel TODO von Tweets erhielt kein Merkmal, welches auf eine Stimmung hinweisen könnte. Die Konsequenz war Teile des Datensatzes manuell und subjektiv zu bewerten (Jochen & Bernhard). In der Abbilung \ref{fig:testdata_bewertet} sind die Bewertungungen mit "sentimentOriginal", den Tweettext mit "full_text" und die Nummerierung mit "X" zu sehen.

![Manuell bewertetes Wörterbuch \label{fig:testdata_bewertet}](Pictures/testdata_bewertet.PNG)

TODO Bevor alles gemacht wurde, wurden die Tweets komplett in einzelne Wörter getrennt, außer beim Vader.

\subsection{Verwendete Wörterbücher}

In diesem Bericht wurden die Wörterbücher "bing", "afinn" und "loughran" aus dem R-Package "tidytext" und das vaderSentiment verwendet (TODO verlinken).

\begin{table}[H]
\centering
\begin{tabular}{l|rrr}
\textbf{Wörterbuch}     & \multicolumn{1}{l}{\textbf{Bewertungsart}} & \multicolumn{1}{l}{\textbf{Intelligenz}} & \multicolumn{1}{l}{\textbf{Programmiersprache}} \\
\hline
\textbf{bing}           & Positiv/Negativ                            & -                                        & R                                               \\
\textbf{afinn}          & -5 bis 5                                   & -                                        & R                                               \\
\textbf{loughran}       & Positiv/Negativ                            & -                                        & R                                               \\
\textbf{vaderSentiment} & -4 bis 4                                   & vaderSentiment                           & Python                                         
\end{tabular}
\caption{Übersicht der verwendeten Wörterbücher}
\label{tab:used_wordbooks}
\end{table}

In der Tabelle \ref{tab:used_wordbooks} sind die verwendeten Wörterbücher mit deren Bewertungsart, ob eine Intelligenz verfügbar und in welcher Programmiersprache dieses Wörterbuch ursprünglich vorhanden war, aufgelistet. Die Wörterbücher "bing" und "loughran" arbeiten mit positiven und negativen Bewertungen, "afinn" arbeitet mit einer Bewertungsreichweite von -5 bis 5, wobei -5 die negativste- und 5 die positivste Stimmung wiederspiegelt. Das Wörterbuch "vaderSentiment" wurde von 10 unabhängigen Menschen manuell mit der Reichweite -4 bis 4 bewertet und davon der Durchschnitt und die Standardabweichung berechnet. Weiterhin wurde eine Logik von den Machern hinterlegt, die Verneinung, Satzzeiten, groß geschriebene Wörter u. v. m. bei der Berechnung des Sentiments beachtet.

Zu Beginn wurden mittels den vier Wörterbüchern ein Sentiment über den Testdatensatz berechnet. Diese Berechnung wurde mittels der Abbildung \ref{fig:ubereinstimmung_nothing} visualisiert. Jeder Block entspricht ein Wörterbuch und jeder Balken spiegelt die Anzahl der Treffer wieder. 

 * Die \textit{Hits} sind die Anzahl der gesamten Treffer.
 * Die \textit{noHits} spiegelt die Anzahl der keinen Treffer wieder.
 * Die \textit{negativen} Treffer sind ausschließlich die Anzahl der negativen Treffer
 * Die \textit{positiven} Treffer sind ausschließlich die Anzahl der positiven Treffer
 * Die \textit{neutralen} Treffer sind ausschließlich die Anzahl der neutralen Treffer

![Anzahl der Übereinstimmungen der vorgesagten und der manuel eingepflegten Sentiments\label{fig:ubereinstimmung_nothing}](Pictures/ubereinstimmung_nothing.PNG)

Die Wörterbücher "bing" und "afinn" liegen können insgesamt um die 70 Übereinstimmungen aufweisen, wohingegen "loughren" knapp über 50 vorweisen kann. Das beste Wörterbuch ist "vader" mit ca. 120 Übereinstimmmungen. Weiterhin ist auffällig, dass "bing", "afinn" und "vader" eine ähnliche Anzahl der Übereinstimmungen bei den positiv bewertenden Tweets aufweisen kann, jedoch punktet "vader" bei den neutralen Tweets, wo er mit ca. 30 Übereinstimmungen mit Abstand der beste ist. 

\subsection{Stemming}

Die Idee hinter Stemming ist das Reduzieren einer Wortvariante auf seinem Wortstamm. Zum Beispiel werden die Worte "Häuser" und "Häusern" zu deren Wortstamm "Haus" reduziert.

Um das Stemming durchzuführen, wurde das R-Package \textit{corpus} verwendet. Die folgenden Varianten des Stemmings wurden durchgeführt.

 * Corpus unterstützt vom Haus aus 17 unterschiedliche Sprachen, um ein Wortstamm zu bilden. Da der gegebene Datensazu nur englische Texte enthält, wurde nur die englische Sprache betrachtet des Standard-Packetes betrachtet.
 * Der \textit{Hunspell stemmer} soll prezisere Stämme bilden.
 * Der \textit{Dictionary stemmer} wird on-the-fly von lexoconista.com als Tupels von (Wörter, Stamm) geladen und danach mittels einer Funtkion den corpus-Package übergeben.
 * Hunspell liefert eine \textit{Rechtschreibkorrektur} mit. Zu erst wird geprüft, ob das Wort im Hunspell-Stemming-Wörterbuch existiert. Falls das Wort existiert, wird der Wortstamm zurück gegeben. Falls das Wort im Hunspell-Stemming-Wörterbuch nicht existiert, werden versucht ähnliche Wörter mittels der bereits existierten Funktion zu finden.
 
Für die gestemmten Tweets wurden die gleichen Auswertungen berechnet, wie in der Abbildung \ref{fig:ubereinstimmung_nothing} zu sehen ist. Dabei stellte sich heraus, dass alle Verfahren bezüglich Stemming den Score verschlechterten. Die einzige Ausnahme gilt der Rechtschreibkorrektur, die insgesamt zwei Tweets mehr erkennt.


\subsection{Ausblick}
TODO

 * Weitere Stemming Verfahren
 * Bessere Rechtschreibkorrektor
 * n-gram



\section{Einfacher Sentimentindex}
Um lokal auf den eigenen Rechnern zur Arbeite, war der erste Schritt die Daten auf den Cuda Rechner auf zu splitten in kleinere Pakete. 

Hier Code Einf?gen 

Wenn Personen einen Text lesen, verwenden sie das Verst?ndnis W?rtern zu deuten, um daraus abzuleiten, ob ein Textabschnitt positiv oder negativ ist, oder vielleicht durch andere nuanciertere Emotionen wie ?berraschung oder Ekel gekennzeichnet ist. Die Werkzeuge des Text Mining werden nun genutzen, um den emotionalen Inhalt von Texte zu analysieren. Zu Beginn soll eine einfache Sentimentindex ?ber die $10$ gr??ten Banken in der Welt erstellt werden. F?r die erste Analyse werden die W?rterb?cher verwendet, die in R implementiert sind. 

\begin{itemize}
\item Im Package tidytext befindet sich das Stopw?rterbuch stop$\_$words
\item Im package tidytex befindet sich die W?rterb?cher afinn und bing.
\end{itemize}

<!-- \newline -->
Die $10$ gr??ten Banken:
\begin{itemize}
\item Prudential Financial Inc
\item Citigroup Inc
\item Goldman Sachs Group Inc/The
\item MetLife Inc
\item Morgan Stanley
\item Voya Financial Inc
\item Lincoln National Corp
\item Principal Financial Group Inc
\item Genworth Financial Inc
\item Hartford Financial Services Group Inc/The
\end{itemize}



<!-- Auflistung der WC6rterbC<cher, Vor- und Nachteil der WC6rterbC<cher -->


\section{Verfahren}




