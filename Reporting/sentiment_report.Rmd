
---
classoption: oneside
documentclass: article
fontsize: 12pt
header-includes:
- \usepackage{amsthm}
- \usepackage{xcolor}
- \usepackage[ngerman]{babel}
- \usepackage[utf8]{inputenc}
- \usepackage{amsmath}
- \usepackage{amsfonts}
- \usepackage{amssymb}
- \usepackage[mathscr]{euscript}
- \usepackage{graphicx}
- \usepackage{subcaption}
- \usepackage{tabularx}
- \usepackage{url}
- \usepackage{hyperref}
- \usepackage[]{algorithm2e}
- \usepackage{mdframed}
- \usepackage{lipsum}
- \usepackage{extarrows}
- \usepackage[most]{tcolorbox}
- \usepackage{color}
- \usepackage{paralist}
- \usepackage{amsthm}
- \usepackage{blindtext}
- \usepackage{fancyhdr}
- \usepackage{colortbl}
- \usepackage{framed}
- \usepackage{float}
- \usepackage{listings}
- \usepackage{fancyhdr}
- \usepackage{geometry}
- \usepackage[onehalfspacing]{setspace}

geometry: top=2.5cm, bottom=2.5cm, left=2.5cm, right=2.5cm

output:
  pdf_document:
    number_sections: yes
---




\newcommand{\mybox}[1]{%
  \tikz[baseline=(text.base)]
    {\node [draw,rounded corners,fill=red!20] (text) {#1};}%
}

\newtheoremstyle{normal}
{10pt} 
{10pt}
{\normalfont}
{}
{\bfseries}
{}
{0.8em}
{\bfseries{\thmname{#1} \thmnumber{#2}\thmnote{ \hspace{0.5em}(#3)\newline}}}
\theoremstyle{normal}

\newtheorem{satz}{Satz}
\newtheorem{defin}{Definition}
\newtheorem{beispiel}{Beispiel}

\pagenumbering{roman}

\numberwithin{equation}{section}
\numberwithin{figure}{section}
\renewcommand{\headrulewidth}{0.5pt}

\lhead{\nouppercase{\rightmark}}\rhead{}
<!-- \renewcommand{\sectionmark}[1]{\markright{\thesection.\ #1}} -->
<!-- \onehalfspacing -->
<!-- \cleardoublepage -->







<!--- Titelseite ---> \input{Titelblatt2} 

<!--- Inhaltsverzeichnis ---> \tableofcontents\newpage
\addcontentsline{toc}{section}{Abbildungsverzeichnis}
<!--- Abbildungsverzeichnis ---> \listoffigures\newpage
\setlength{\parindent}{0pt} 
\renewcommand{\footrulewidth}{1pt}
\pagenumbering{arabic}

<!--- Beginn --->
\section{Ergebnisse} 
Wenn Leser einen Text analysieren, verwenden sie, dass Verständnis der emotionalen Absicht von Wörtern, um daraus abzuleiten, ob ein Textabschnitt positiv oder negativ ist.
Das Ziel dieser Ausarbeitung ist einen Zusammenhang zwischen dieser Stimmung (\textit{Sentiment}) der Tweets bezüglich dem Finanzbereich aus dem Jahr $2012$ und Aktienindizes nachzuweisen. 
<!-- Wörding wirtschaftliche Ereignisse -->
Unsere Annahme ist, dass wirtschaftliche Ereignisse sich schneller auf die sozialen Medien verbreiten. Dies nehmen wir als Anhaltspunkt und versuchen Ereignisse am Aktienindex vorherzusagen.

Als Beispiel dient die Griechenlandkrise im Jahr $2012$. Zu der Zeit der Griechenlandkrise sind viele Hashtags entstanden und die Bürger der EU haben ihre Meinung in Tweets kundgetan. Hashtags die sich auf wichtige politische Entscheidungen im Zusammenhang der Griechenlandkrise sich beziehen, waren zum Beispiel \#Grexit,\#G7, \#Greferendum und \#EuroGipfel. Unter diesen Hashtags haben sich gewisse Informationen schnellverbreit. Diese Information hatten, im späteren einen gewissen Einfluss auf die Aktienindizes.

Mittels Textmining sollen diese Informationen aus den Tweets in einen Sentimentindex umgewandelt werden. Mit diesem Sentimentindex wird versucht Aktienindizes vorherszusagen, durch Regression. Auf der Abbildung \ref{Reg_afinn1} ist eine Regression auf wöchentlichen prozentualen Veränderungen der Aktienindizes dargestellt. 


<!--Mittels erzeugten Sentimentindizies aus den Tweets können Zusammenhänge sichtbar gemacht und Regressionen auf Aktienindizes durchgeführt werden.--> 

 \begin{figure}[H]
   	\centering
  \includegraphics[width=1\textwidth]{Pictures/Afinn_plot.png}
   	\caption{Multiple Regression mittels Sentimenindex auf einen Aktienindex}\label{Reg_afinn1}
\end{figure}
Die nächsten Seiten werden thematisch die Aufbereitung der Daten, die richtige Wahl des Wörtberuchs, den Zusammenhang zwischen Aktienindizes und Sentimentindizes und die vorgestellte Regression auf Aktienindizes.

<!-- Würde Einführung und Aufgabenbeschreibung weglassen, da dies ja beides implizit in den Resultaten gesagt wird, oder? BP -->
<!--\section{Einführung}
Wenn Leser einen Text analysieren, verwenden sie, dass Verständnis der emotionalen Absicht von Wörtern, um daraus abzuleiten, ob ein Textabschnitt positiv oder negativ ist, oder ob er vielleicht durch eine andere nuanciertere Emotion wie Überraschung oder Ekel gekennzeichnet ist.-->
<!-- Sachen wir wir evtl. benötigen, oder soll das weggelassen werden? -->
\section{Aufgabenbeschreibung} 
Eine Sentiment Analyse soll über die Banken von USA und Europa mittels den Twitterdaten auf dem Cuda erstellt werden. Die Twitterdaten liegen als R-Dataframe vor. Die Tabelle zeigt den Aufbau des DataFrames und die benötigten Daten. 

\begin{table}[H]
  \centering
  \begin{tabular}{lrrrr}
	Tweets & Follower			& favourites\_count			& friends\_count			& ... \\
    \hline
    My twit pic is sexy	& 81	& 101	& 3523	& 85 \\
    I am I really this tired	& 233	& 517	& 23542	& 99 \\
    F5 Copy	& 181	& 345	& 2672	& 99 \\
  \end{tabular}
  \caption{Ein Ausschnitt des DataFrames vom Cuda} \label{tab:example_dataframe_twits}
\end{table}

<!-- Vielleicht irgendwo die Definition eines Sentiments? -->
<!-- Wo kommen die Daten her? Welches Format hatten die Daten? Welches Format benutzen wird? -->
\section{Daten}
Der Sentiment ist die Stimmung bzw. die Emotion des Schreibers die der Textbeinhaltet.
Ein Sentiment wird aus Texten, indem Anwender ihre Meinungen wiedergeben, gewonnen. Als Datengrundlage dient uns das Twitterarchive und die Twitter-API, siehe Unterkapitel \ref{sub:twitter_archive} und \ref{sub:scanned_data}. Um die errechneten Sentiments vergleichen zu können, wurde der Dow Jones Industrial 30 Aktienindex aus dem Jahr 2012 verwendet, siehe Unterkapitel \ref{sub:dow_jones_data}.


\subsection{Twitterarchive}
\label{sub:twitter_archive}
Twitter veröffentlicht monatlich $1$ \% ihrer gesamten Tweets auf \textit{archive.org}[TODO Referen?]. Dieses Twitterarchive wurde auf dem hauseigenen CUDA-Rechner aus dem Jahre $2012$ in einem R-spezifischen DataFrame aufbereitet und zur Verfügung gestellt. Da diese Archive alle Tweets enthält, auch Tweets die themenfremd sind, wurde ein Filter gebaut, der die benötigten Daten filtert.

![Filter für grieschiche Banken \label{fig:filter}](Pictures/filter_twitter_archive.PNG)

In Abbildung \ref{fig:filter} ist einer unserer Filter für die grieschichen Banken zu sehen. Die Begriffe, nachdem gefiltert wird, sind in grün zu sehen. Diese sind jeweils durch einem logischen \textit{Oder} getrennt. Wird ein Begriff in einem Tweet gefunden, wurde dieser Tweet in unserem Datenbestand mitaufgenommen. 

Eine große Herausforderung war das Finden sinnvoller Filter. Ist der Filter nicht wohlwollend gewählt, könnten folgende Fälle eintreten, die sich negativ auf dem Sentiment auswirken könnten.

 * Ist ein Filter zu allgemein gewählt, besteht die Möglichkeit in Überschneidungen mit weiteren nicht bezogenen Themen zu laufen. Beispielsweise ist der Filter \textit{Bank} sehr allgemein gewählt, da die Bank im Park oder die Bank im Glücksspiel gemeint sein könnte. An dieser Stelle besteht die Möglichkeit die Anzahl der nicht gewollten Tweets abzuwägen. Sind diese anteilig gering, kann der Filter aufgenommen werden.
 * Ist ein Filter zu speziell gewählt, besteht die Möglichkeit zu wenige Tweets zu finden.

Die Wahl der Begriffe ist demnach ein Trade-Off zwischen der Noise, die Anzahl der nicht relevanten Themen, und die Anzahl der gesamten Tweets, die nach dem Filtern übrig bleibt. Werden die Begriffe zu allgemein gewählt, werden viele Tweets einbezogen, jedoch könnte dadurch die Noise sehr hoch werden. Werden die Filter zu streng gewählt, besteht die Möglichkeit zu wenige Tweets nach dem Filtern einzubeziehen.

Insgesamt haben wir ca. $17.000$ Tweets durch die gewählten Filter über das gesamte Jahre $2012$ gefiltert. Da das Sentiment wöchentlich gebildet wird, sind das ca. $325$ Tweets pro Woche.

\subsection{Twitter-API}
\label{sub:scanned_data}
Zu Beginn war uns nicht klar, ob ausreichend Daten durch das Twitterarchive gewonnen werden können. Dadurch ergab sich die Idee, die Twitter-API zusätzlich zu verwenden. Die Twitter-API erlaubt $450$ Anfragen alle $15$ Minuten. Der Kern des PHP-Skriptes wird durch folgenden Code erleutert. TODO Verlinkung

```php
// Query with one Hashtag and a limit up to 100
// GET call
$getfield = '?q=' . $hastag . '&
              result_type=recent&
              count=100&
              tweet_mode=extended';

// Setting up the Twitter-API
$twitter = new TwitterAPIExchange($this->settings);

// Perform the request
$data = $twitter->setGetfield($getfield)
                ->buildOauth($this->url, $this->requestMethod)
                ->performRequest();
```
Der obige Code zeigt die Abfrage eines Hastags. Die verschiedenen Hashtags werden mittels einer Schleife iteriert. Der Abruf (GET) wird mit einem URL Aufruf realisiert, der mit unterschiedlichen Einstellungen, wie Anzahl der maximalen Tweets (\textit{100}), welcher Typ (\textit{recent}) und in welchen Mode (\textit{extended}) werden die Tweets zurück gegeben, aufgerufen werden kann. Als nächstes werden die Settings übergeben. Die Twitter-spezifischen Settings werden nach der Registration im Entwicklungsbereich auf deren Webseite von generiert. Danach wird die Abfrage mittels der Twitter-Klasse realisiert. Die Rückgabe enthält ein Array im JSON-Format mit den letzten 100 Tweets. Zum Speichern werden die Tweets aufbereitet und als JSON-Format gespeichert.

Aktuell muss das Skript manuell ausgeführt werden. Dieses Problem haben wir durch ein \textit{Cronjob} gelöst. Ein Cronjob führt in definierten Intervallen oder an definierten Zeitpunkten ein Event, in unserem Fall eine PHP-Datei, aus. An dieser Stelle wurde entschieden die höher frequentierten Tweets auf einem zwei Minuten Intervall und weniger frequentierten Tweets auf einem 15 Minuten Intervall zu setzen.



<!-- Link evtl. in die Referenz? -->
<!-- Anschließend wird die wöchentliche Veränderung berechnet? -->
\subsection{Aufbereitung des Dow Jones Industrial 30 Aktienindex aus 2012}
\label{sub:dow_jones_data}
Der \textit{Dow-Jones-Industrial} 30 Index misst die Entwicklung des US-amerikanischen Aktienmarktes. Der Dow-Jones-Index an der New York Stock Exchange (NYSE) ist einer der älteste noch bestehende Aktienindex der USA und setzt sich heute aus $30$ den größten US-Unternehmen zusammen. Der tägliche Aktienindex des \textit{Dow-Jones-Industrial} 30 $2012$, der für die späteren Regressionen verwendet wird, stammt von der Seite \url{http://www.boerse-online.de/index/historisch/dow_jones/1.1.2012_31.12.2012}.
Die Daten werden in eine Excel-Datei überführt. Anschließend wird die wöchentliche Veränderung des Aktenindex in Prozent berechnet. In der Abbildung \ref{picture:dow_jones} ist ein Auschnitt der aufbereiteten Daten zu sehen.
 \begin{figure}[H]
   	\centering
  \includegraphics[width=1\textwidth]{Pictures/Dow_jownes.png}
   	\caption{Ausschnitt des aufbereiteten \textit{Dow Jones Industrial} $30$ Aktienindexes}
   	\label{picture:dow_jones}
 \end{figure}



\subsection{Datenaufbereitung}
\label{sub:datenaufbereitung}
Für die Berechnung der Sentimentindizes werden ausschließlich Tweets betrachtet die mit dem sprachlichen Kürzel \textit{eng} gekennzeichnet sind. <!-- Passt der Satz hier überhaupt ins Kapitel? Bzw. den Filter habe ich ja schon vorher kurz angesprochen TODO -->Es werden Indizes für Europa und die USA gebaut, über die Tweets der Banken.

<!-- Würde den obigen Text weglassen und dafür ab hier beginnen? TODO -->
Im Folgendem werden die einzelnen Schritte für die Aufbereitung der Daten beschrieben, die notwendig sind, um verschiedene Sentimentindizes zu berechnen, auf Basis von Wörterbüchern. Hierzu werden eigens programmierten Funktionen benutzt.


<!--  Um mit den Daten besser arbeiten zu können, müssen die Tweets mit einer Spalte \textit{Month2} und \textit{week} ergänzt werden. Mit den Spalten \textit{Month2} und \textit{week} können Indizies für Monaten und Wochen berechnet werden, dafür wird die Funktion \textit{Kalenderwochen} verwendet. -->
<!-- Welche erzeugten CSV Dateien? In Was umgewandelt? TODO -->
\begin{enumerate}
\item Die erzeugten CSV-Datei mit den gefilterten Tweets werden mit der Funktion \textit{Datei$\_$einlesen} eingelesen und in ein Dataframe umgewandelt.
\item Um ein Vergleich mit dem Dow Jones aus \ref{sub:dow_jones_data} zu ermöglichen, wurden die Wochen- und Monatsnummer des Twitterarchivs \ref{sub:twitter_archive} berechnet und aufgenommen (\textit{Month2} \& \textit{week}). 
\item Die doppelten Tweets wurden mittels der Funktion \textit{Distinct} gefiltert.
\item Mit der Funktion \textit{clearing$\_$dataframe} werden die Texte der Tweets in einzelnen Wörter aufgesplittet. Damit besteht ein Tweet aus mehreren Zeilen und eine Zeile jeweils nur aus einem Wort. Anschließend wird das Dataframe von Stopwörtern bereinigt, die in der Wörterliste \textit{Stopwords} enthalten sind. Das Wörterbuch steht in R zur Verfügung. Im Kapitel Wörterbuch \ref{Woerterbuch} sind diese beschrieben. Die Tabelle \ref{tab:dataaufbereitung} zeigt einen Ausschnitt des aufbereitenden Dataframes. Dieses Dataframe gilt als Grundlage für die nächsten Kapitel. 


\begin{table}[H]
\centering
\caption{Aufbereites Dataframe}
\label{tab:dataaufbereitung}
\begin{tabular}{|l|l|l|l|l|l|l|l|}
\hline
\textbf{id} & \textbf{X} & \textbf{Language} & \textbf{Follower} & \textbf{favourites\_coun} & \dots & Month2 & week \\ \hline
2           & 12         & en                & 1114              & 0                         &              & 1      & 1    \\ \hline
3           & 12         & en                & 114               & 0                         &              & 1      & 1    \\ \hline
 \vdots           &   \vdots           &  \vdots                  &  \vdots                 &  \vdots                         &  \dots            &  \vdots      &  \vdots    \\ \hline
12          & 13         & en                & 319               & 0                         &              & 1      & 1    \\ \hline
13          & 13         & en                & 319               & 0                         &              & 1      & 1    \\ \hline
\end{tabular}
\end{table}
\end{enumerate}
<!-- Evtl. die Kapitel aufzählen TODO -->
<!-- Die Tabelle vielleicht bis zum Ende führen? TODO -->



\section{Wörterbücher}
\label{Woerterbuch}
Ein Mensch ist in der Lage nachdem Lesen eines Textes zu beurteilen welche Stimmung dieser wiederspiegelt. Das Tweetbeispiel "Der Kurs ist gut! #bitcoin" spiegelt eine positive Resonanz bezüglich Bitcoin wieder. Im Textmining ist die Taktik die einzelnen Wörter oder Wortgruppen (n-gramms) zu betrachten und mittels einem Wörterbuch die Stimmung einzuteilen. Bevor ein Sentimentindex (Stimmungsindex) über einem Tweet erstellt wird, müssen die Stimmungen aus dem jeweiligen Tweet mittels ein oder mehreren Wörterbüchern extrahiert werden. 


Ein Wörterbuch, auch Lexika genannt, besteht aus einer Liste von Wörtern, die von einem oder mehreren Individuen bewertet wurden. Die Bewertung kann 1/0, Negativ/Positive, 0-10, eine Stimmung u. s. w. sein. Die Abbildung \ref{fig:worterbuch} zeigt ein Wörterbuch aus dem R-Package \textit{tidytext}. Die Spalte \textit{word} steht für das bewertende Wort und \textit{sentiment} für deren Bewertung.

![Positiv/Negativ Wörterbuch \label{fig:worterbuch}](Pictures/worterbuch.PNG)

Ein \textbf{Hononym} ist der Begriff für die Doppeldeutigkeit eines Wortes, zum Beispiel \textit{Bank}. Wird ein Wort für ein Wörterbuch bewertet, muss der Kontext in dem sich das Wörterbuch befindet, beachtet werden. Angenommen es existieren zwei Wörterbücher, wobei jeweils eins für die Natur und  eins für den Immobiliensektor abgestimmt ist. Das Wort \textit{Bank} kann in diesem Fall zwei unterschiedliche Bewertung erhalten. In der Natur könnte eine Bank eher als positiv bewertet werden, wohingegen die Bank für den Immobiliensektor eher negativ ausgelegt werden könnte.

Um die \textbf{Güte eines Wörterbuches} beurteilen zu können, werden Tweets benötigt, die in irgendeiner Art und Weise eine Bewertung beinhalten. Der gegebene Datensatz aus Kapitel \ref{sub:scanned_data} von Tweets erhielt kein Merkmal, welches auf eine Stimmung hinweisen könnte. Die Konsequenz war Teile des Datensatzes manuell und subjektiv zu bewerten. In der Abbilung \ref{fig:testdata_bewertet} sind die Bewertungungen mit \textit{sentimentOriginal}, den Tweettext mit \textit{full\_text} und die Nummerierung mit \textit{X} zu sehen.

![Manuell bewertetes Wörterbuch \label{fig:testdata_bewertet}](Pictures/testdata_bewertet.PNG)

\subsection{Verwendete Wörterbücher}

In diesem Bericht wurden die Wörterbücher \textit{bing}, \textit{afinn} und \textit{loughran} aus dem R-Package \textit{tidytext} und das vaderSentiment verwendet (TODO verlinken, bzw. in der Referenz erwähnen). Diese bestehen aus Unigrammen (einzelne Wörter).

\begin{table}[H]
\centering
\begin{tabular}{l|rrr}
\textbf{Wörterbuch}     & \multicolumn{1}{l}{\textbf{Bewertungsart}} & \multicolumn{1}{l}{\textbf{Intelligenz}} & \multicolumn{1}{l}{\textbf{Programmiersprache}} \\
\hline
\textbf{bing}           & Positiv/Negativ                            & -                                        & R                                               \\
\textbf{afinn}          & -5 bis 5                                   & -                                        & R                                               \\
\textbf{loughran}       & Positiv/Negativ                            & -                                        & R                                               \\
\textbf{vaderSentiment} & -4 bis 4                                   & vaderSentiment                           & Python                                         
\end{tabular}
\caption{Übersicht der verwendeten Wörterbücher}
\label{tab:used_wordbooks}
\end{table}

In Tabelle \ref{tab:used_wordbooks} sind die verwendeten Wörterbücher mit deren Bewertungsart, ob eine Intelligenz verfügbar und in welcher Programmiersprache dieses Wörterbuch ursprünglich vorhanden war, aufgelistet. Die Wörterbücher "bing" und "loughran" arbeiten mit positiven und negativen Bewertungen, "afinn" arbeitet mit einer Bewertungsreichweite von -5 bis 5, wobei -5 die negativste- und 5 die positivste Stimmung wiederspiegelt. Das Wörterbuch "vaderSentiment" wurde von 10 unabhängigen Menschen manuell mit der Reichweite -4 bis 4 bewertet und davon der Durchschnitt und die Standardabweichung berechnet. Weiterhin wurde eine Logik von den Machern hinterlegt, die Verneinung, Satzzeiten, groß geschriebene Wörter u. v. m. bei der Berechnung des Sentiments beachtet.


Zu Beginn wurden mittels den vier Wörterbüchern ein Sentiment über den Testdatensatz berechnet. Diese Berechnung wurde mittels der Abbildung \ref{fig:ubereinstimmung_nothing} visualisiert. Jeder Block entspricht ein Wörterbuch und jeder Balken spiegelt die Anzahl der Treffer wieder. 

 * Die \textit{Hits} sind die Anzahl der gesamten Treffer.
 * Die \textit{noHits} spiegelt die Anzahl der keinen Treffer wieder.
 * Die \textit{negativen} Treffer sind ausschließlich die Anzahl der negativen Treffer
 * Die \textit{positiven} Treffer sind ausschließlich die Anzahl der positiven Treffer
 * Die \textit{neutralen} Treffer sind ausschließlich die Anzahl der neutralen Treffer

![Anzahl der Übereinstimmungen der vorhergesagten und der manuel eingepflegten Sentiments\label{fig:ubereinstimmung_nothing}](Pictures/ubereinstimmung_nothing.PNG)

Die Wörterbücher "bing" und "afinn" liegen können insgesamt um die 70 Übereinstimmungen aufweisen, wohingegen "loughren" knapp über 50 vorweisen kann. Das beste Wörterbuch ist "vader" mit ca. 120 Übereinstimmmungen. Eine weitere Auffälligkeit bezüglich "bing", "afinn" und "vader" sind die Anzahl der Übereinstimmungen im Bereich der positiv bewertenden Tweets. Jedoch punktet "vader" bei den neutralen Tweets, wo er mit ca. 30 Übereinstimmungen die beste Performance liefert.

\subsection{Stemming}

Die Idee hinter Stemming ist das Reduzieren einer Wortvariante auf seinem Wortstamm. Zum Beispiel werden die Worte "Häuser" und "Häusern" zu deren Wortstamm "Haus" reduziert.

Um das Stemming durchzuführen, wurde das R-Package \textit{corpus} verwendet. Die folgenden Varianten des Stemmings wurden durchgeführt.

 * Corpus unterstützt vom Haus aus 17 unterschiedliche Sprachen, um ein Wortstamm zu bilden. Da der gegebene Datensazu nur englische Texte enthält, wurde nur die englische Sprache betrachtet des Standard-Packetes betrachtet.
 * Der \textit{Hunspell stemmer} soll prezisere Stämme bilden.
 * Der \textit{Dictionary stemmer} wird on-the-fly von lexoconista.com als Tupels von (Wörter, Stamm) geladen und danach mittels einer Funtkion den corpus-Package übergeben.
 * Hunspell liefert eine \textit{Rechtschreibkorrektur} mit. Zu Beginn wird geprüft, ob das Wort im Hunspell-Stemming-Wörterbuch existiert. Falls das Wort existiert, wird der Wortstamm zurück gegeben. Falls das Wort im Hunspell-Stemming-Wörterbuch nicht existiert, wird versucht ähnliche Wörter mittels der bereits existierten Funktion zu finden.
 
Für die gestemmten Tweets wurden die gleichen Auswertungen berechnet, wie in Abbildung \ref{fig:ubereinstimmung_nothing} zu sehen ist. Dabei verschlechterten alle Stemming-Verfahren den Score. Die einzige Ausnahme gilt der Rechtschreibkorrektur, die insgesamt zwei Tweets mehr erkennt.
<!-- TODO Referenz? --> 

<!--\section{Berechnung der Sentimentindizes}
Für die Berechnung von Sentimentindizes wird nach dem Buch \textit{Text Mining with R} von \textit{Julia Silge and David Robinson} vorgegangen. Im Buch \textit{Text Mining with R} werden die Sentimentindizes mittels dem Prinzip \textit{tidy data} in R erstellt. Ein Beispiel für einen einfachen Sentimentindex, der positive und negative Wörter für jede Woche zählt, soll vorgestellt werden. Zur Berechnung des Sentimenindex wird das vorbereitete Dataframe aus dem Kaptiel \textit{Datenaufbereitung} benutzt. Zuerst wird der vorbereitete Dataframe mit dem Wörterbuch \textit{Bing} gejoint mit der gleichnamige Spalte \textit{word}. Im Anschluss wird der Dataframe gruppiert nach Wochen und dabei werden die verschiedene  Ausprägungen (\textit{positiv} und \textit{negativ}) in der Spalte \textit{Sentiment} gezählt. Für die gezählten Ausprägungen pro Woche entsteht eine neue Spalte \textit{n}. In der Spalte \textit{Sentiment} stehen die Wörter (Ausprägungen) \textit{positiv} oder \textit{negativ} passend zu dem Wort in der Spalte \textit{word} im Datensatz. Um einen Index pro Woch zu berechnen, wird eine Spalte für jede Ausprägung mit ihrer Anzahl pro Woche erzeugt, aus den Spalten \textit{Sentiment} und $n$. Zum Schluss wird eine neue Spalte \textit{Sentiment} gebildet, indem die Anzahl der positiven minus den negativen Wörter stehen ($Sentiment=positiv-negativ$). Der Sentimentindex \textit{Sentiment} wird als Barplot dargestellt.
```{r  eval=FALSE, echo=FALSE}
source("../Testing/SentimentFunctionChris.R")
#source("varianz.R")
source("../Testing/functions.R")
pakete_lade()
#Aufbereitung der Daten----------------------------------
 file<-"../Testing/Daten2012usa.csv"
 daten_usa<-Datei_einlesen(file)

kalenderwochen_hinzufuegen<-Kalenderwochen(daten_usa)
daten_doppelt_loeschen<-Distinct(kalenderwochen_hinzufuegen)
clearing_data<- clearing_dataframe(daten_doppelt_loeschen)
```

```{r eval=FALSE, echo=TRUE}

  bing <- get_sentiments("bing")
    differenz_positive_negative<-  clearing_data  %>%
      inner_join(bing) %>%
      group_by(week)%>%
      count(sentiment) %>%
      spread(sentiment, n)%>%
      mutate(sentiment = positive - negative)
``` 

```{r eval=FALSE, echo=TRUE}
differenz_positive_negative    
ggplot(data= differenz_positive_negative, 
       es(x=week, y=sentiment),fill=sentiment) +geom_col(show.legend = FALSE)
      +geom_bar(stat="identity",  fill="blue",colour="black")
      +xlab("Wochen")+ylab("Sentimentindex")
```

 \begin{figure}[H]
   	\centering
  \includegraphics[width=1\textwidth]{Pictures/sentiment_bing_week.png}
   	\caption{Sentimentindex: monatlicher Mittelwert TODO}
 \end{figure}

In der unteren Aufzählung werden einige Sentimentindizes berechnet, die von uns in R implementiert wurde. Die Funktionen der aufgezählten Sentimentindizes werden in der R-Datei \textit{SentimentFunctionChris.R} bereitgestellt. Bei allen Funktionen müssen zwei Parameter übergeben werden, den vorbereitete Dataframe und einen String (\textit{Woche} und \textit{Monat}) der angbit, ob ein Sentiment pro Woche oder pro Monat berechnet wird. 
\begin{itemize}
\item \textit{Wörterbuch Bing:} Einzelene Tweets werden als negative, positive oder als neutral gekennzeichnet. Die Tweets die mehr positive als negative Wörter besitzen, werden als positve makiert anders herum als negative, bei gleichstand als neutral.
 \begin{figure}[H]
\centering
 	\includegraphics[width=1\textwidth]{Pictures/tweetebene.png}
 	\caption{Sentimentindex auf Tweetebene}
\end{figure}

\item \textit{Wörterbuch AFINN:} Die Funktion \textit{afinn$\_$score$\_$wert} bildet den Mittelwert pro Woche und Monat.
 \begin{figure}[H]
\centering
 	\includegraphics[width=1\textwidth]{Pictures/afinn_mittelwert.png}
 	\caption{Sentimentindex auf Tweetebene}
\end{figure}
\end{itemize}

-->

```{r eval=FALSE, echo=TRUE}

  bing <- get_sentiments("bing")
    differenz_positive_negative<-  clearing_data  %>%
      inner_join(bing) %>%
      group_by(week)%>%
      count(sentiment) %>%
      spread(sentiment, n)%>%
      mutate(sentiment = positive - negative)
``` 
\section{Analysen von Tweets und ihrer Sentimentindizies}
<!-- TODO, sollen wir hier nicht vielleicht die Akündigung der Methoden und Mitteln weglassen und direkt einsteigen? -->
In diesem Abschnitt soll umrissen werden, mit welcher Methoden und Mitteln verwenden kann, um Tweets und Sentimentindizes zu analysieren. Um einen ersten Eindruck von den Tweets zu bekommen, ist es von Vorteil die am häufigsten vorkommenden positivsten und negativsten Wörter zu visualisieren. Die Visualisierung wird mittels einem Balkendiagramm umgesetzt.
 \begin{figure}[H]
\centering
 	\includegraphics[width=1\textwidth]{Pictures/positv_negativ.png}
 	\caption{Barplot der 10 am häufigsten vorkommenden positivsten und negativsten Wörter} \label{barplot}
\end{figure}
```{r eval=FALSE, echo=FALSE}

par(mfrow=c(2,2))
 bing <- get_sentiments("bing")
  word_cloud_usa<- clearing_data  %>%
    inner_join(bing) %>%
    count(word, sentiment, sort = TRUE) %>%
    acast(word ~ sentiment, value.var = "n", fill = 0) %>%
    comparison.cloud(colors = c("#F8766D", "#00BFC4"),
                     max.words = 100)
  
wordcount <- clearing_data  %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment, sort = TRUE) %>%
  ungroup()

wordcount %>%
  group_by(sentiment) %>%
  top_n(10) %>%
  ungroup() %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~sentiment, scales = "free_y") +
  labs(y = "Contribution to sentiment",
       x = NULL) +
  coord_flip()

```

\input{Woertbuchana}


\section{Fazit}
In dem Kapitel \ref{Woerterbuch} wurden 4 verschiedene Wörterbücher und 4 verschiedene Stemming-Verfahren, wobei ein Verfahren die Rechtschreibkorrektur ist, verwendet. Neben weiteren Wörterbüchern, Stemming-Verfahren und besseren Rechtschreibkorrekturen besteht die Möglichkeit anstatt 1-gram (Unigrammen) mit 2-gramme (Bigramme) oder 3-gramme zu arbeiten. Das bedeutet dementsprechend angepasst Wörterbücher zu verwenden. Laut dem [Paper 5 TODO] ist dieser Ansatz sehr vielversprechend.

Der Abschnitt für den Vergleich der verschiedenen Sentimentindizes hat die Schlussfolgerung, dass die verschiedenen Sentimenindizes der Wörterbücher \textit{Wader}, \textit{Bing}, \textit{loughran}, \textit{nrc} und \textit{Afinn} ein ähnliches Verhalten aufweisen. Das Kapitel \ref{ueberein} wurden Gemeinsamkeiten in den zeitlichen Abläufe zwischen den Sentimentindizes und den Aktienindizes untersucht. In vielen Abschnitten wurde eine ähnliche Tendenz eines ähnlichen Verhaltens efasst. Der nächste Schritt wäre eine Korrelation zwischen den beiden Zeitreihen nachzuweisen und somit die zunächst nur auf visuale Beurteilung zu untermauern.

Die Ergebnisse aus dem Kapitel \textit{Model} zeigen, dass Sie  geringefüge neue Informationen liefern um die wöchentliche prozentuale Veränderung des Aktienindiexes zu erklären. Dieses Ergebniss ist nicht ungewöhnlich. Es wird davon ausgegangen, dass die Sentimentindizes und der Aktienidex sehr stark korrelieren müssten, da Sie von den gleichen Faktoren beeinflusst werden. Daher ist es umso erstaunlicher, dass überhaupt ein erster Hinweis erbracht werden konnte, dass die Sentimentindizes noch Informationen beinhalten, die die Aktienindizes erklären können.

\section{Ausblick}
Der nachstehende Text soll einen kurzen Ausblick über weitere Vorgehensweise geben.

Ein weiterer interessanter Ansatz, um die Stimmung in den Tweets zu messen, ist das Verwenden mehrere Wörterbücher und deren Ergebnisse durch ein Votum entscheiden zu lassen. Angenommen drei Wörterbücher beurteilen ein Tweet. Zwei Wörterbücher beurteilen den Tweet als negativ und das dritte Wörterbuch als positiv. Im nächsten Schritt wird durch das Votum der Tweet als negativ klassifiziert, da mehr Wörterbücher den Tweet als negativ eingestuft hatten. Eine Verfeinerung des Votums ist durch eine mögliche Gewichtung der Wörterbücher möglich.

Außerdem besteht die Möglichkeit eine Logik mit den Wörterbüchern zu verknüpfen. Die Logik könnte in der Lage sein gute Verneinungen zu erkennen, wie 	\glqq Der Kurs ist nicht schlecht! #bitcoin\grqq{}. Um den Zusammenhang zwischen den Sentimentindizes und den Aktienindizes besser zu Beurteilen zu können, wäre es nötig sich $2-3$ Jahre die Sentimenindizes und den Aktienindizes an zu sehen und zu analysieren. Außerdem kann bei der multiplen Regression noch verschiedenste ansätze ausprobiert werden, wie zum Beispiel nicht lineare Regression oder auch die variantion der Regressoren. Ein Ansatz um die Targets (Aktienindizes) besser anhand der Sentimenindizes zu erklären wäre die Zeitreihenanalyse. Bei der Zeitreihenanalyse werden eine zeitabhängige Folge von Datenpunkten betrachtet. 




-------------------------------------------------------------------------------------
In dem Kapitel \ref{Woerterbuch} wurden 4 verschiedene Wörterbücher und 4 verschiedene Stemming-Verfahren, wobei ein Verfahren die Rechtschreibkorrektur ist, verwendet. Neben weiteren Wörterbüchern, Stemming-Verfahren und besseren Rechtschreibkorrekturen besteht die Möglichkeit anstatt 1-gram (Unigrammen) mit 2-gramme (Bigramme) oder 3-gramme zu arbeiten. Das bedeutet dementsprechend angepasst Wörterbücher zu verwenden. Laut dem [Paper 5 TODO] ist dieser Ansatz sehr vielversprechend.

Ein weiterer interessanter Ansatz ist das Verwenden mehrere Wörterbücher und deren Ergebnisse durch ein Votum entscheiden zu lassen. Angenommen drei Wörterbücher beurteilen ein Tweet. Zwei Wörterbücher beurteilen den Tweet als negativ und das dritte Wörterbuch als positiv. Im nächsten Schritt wird durch das Votum der Tweet als negativ klassifiziert, da mehr Wörterbücher den Tweet als negativ eingestuft hatten. Eine Verfeinerung des Votums ist durch eine mögliche Gewichtung der Wörterbücher möglich.

Außerdem besteht die Möglichkeit eine Logik mit den Wörterbüchern zu verknüpfen. Die Logik könnte in der Lage sein gute Ve
\begin{appendix}
\section{Berechnung der Sentimentindizes}
Für die Berechnung von Sentimentindizes wird nach dem Buch \textit{Text Mining with R} von \textit{Julia Silge and David Robinson} vorgegangen. Im Buch \textit{Text Mining with R} werden die Sentimentindizes mittels dem Prinzip \textit{tidy data} in R erstellt. Ein Beispiel für einen einfachen Sentimentindex, der positive und negative Wörter für jede Woche zählt, soll vorgestellt werden. Zur Berechnung des Sentimenindex wird das vorbereitete Dataframe aus dem Kaptiel \textit{Datenaufbereitung} benutzt. Zuerst wird der vorbereitete Dataframe mit dem Wörterbuch \textit{Bing} gejoint mit der gleichnamige Spalte \textit{word}. Im Anschluss wird der Dataframe gruppiert nach Wochen und dabei werden die verschiedene  Ausprägungen (\textit{positiv} und \textit{negativ}) in der Spalte \textit{Sentiment} gezählt. Für die gezählten Ausprägungen pro Woche entsteht eine neue Spalte \textit{n}. In der Spalte \textit{Sentiment} stehen die Wörter (Ausprägungen) \textit{positiv} oder \textit{negativ} passend zu dem Wort in der Spalte \textit{word} im Datensatz. Um einen Index pro Woch zu berechnen, wird eine Spalte für jede Ausprägung mit ihrer Anzahl pro Woche erzeugt, aus den Spalten \textit{Sentiment} und $n$. Zum Schluss wird eine neue Spalte \textit{Sentiment} gebildet, indem die Anzahl der positiven minus den negativen Wörter stehen ($Sentiment=positiv-negativ$). Der Sentimentindex \textit{Sentiment} wird als Barplot dargestellt.
```{r  eval=FALSE, echo=FALSE}
source("../Testing/SentimentFunctionChris.R")
#source("varianz.R")
source("../Testing/functions.R")
pakete_lade()
#Aufbereitung der Daten----------------------------------
 file<-"../Testing/Daten2012usa.csv"
 daten_usa<-Datei_einlesen(file)

kalenderwochen_hinzufuegen<-Kalenderwochen(daten_usa)
daten_doppelt_loeschen<-Distinct(kalenderwochen_hinzufuegen)
clearing_data<- clearing_dataframe(daten_doppelt_loeschen)
```

```{r eval=FALSE, echo=FALSE}
   bing <- get_sentiments("bing")
    differenz_positive_negative<-  clearing_data  %>%
      inner_join(bing) %>%
      group_by(week)%>%
      count(sentiment) %>%
      spread(sentiment, n)%>%
      mutate(sentiment = positive - negative)
``` 
<!--
```{r eval=FALSE, echo=FALSE}
differenz_positive_negative    
ggplot(data= differenz_positive_negative, 
       es(x=week, y=sentiment),fill=sentiment) +geom_col(show.legend = FALSE)
      +geom_bar(stat="identity",  fill="blue",colour="black")
      +xlab("Wochen")+ylab("Sentimentindex")
```
-->
 \begin{figure}[H]
   	\centering
  \includegraphics[width=1\textwidth]{Pictures/sentiment_bing_week.png}
   	\caption{Sentimentindex: monatlicher Mittelwert TODO}
 \end{figure}

In der unteren Aufzählung werden einige Sentimentindizes berechnet, die von uns in R implementiert wurde. Die Funktionen der aufgezählten Sentimentindizes werden in der R-Datei \textit{SentimentFunctionChris.R} bereitgestellt. Bei allen Funktionen müssen zwei Parameter übergeben werden, den vorbereitete Dataframe und einen String (\textit{Woche} und \textit{Monat}) der angbit, ob ein Sentiment pro Woche oder pro Monat berechnet wird. 
\begin{itemize}
\item \textit{Wörterbuch Bing:} Einzelene Tweets werden als negative, positive oder als neutral gekennzeichnet. Die Tweets die mehr positive als negative Wörter besitzen, werden als positve makiert anders herum als negative, bei gleichstand als neutral.
 \begin{figure}[H]
\centering
 	\includegraphics[width=1\textwidth]{Pictures/tweetebene.png}
 	\caption{Sentimentindex auf Tweetebene}
\end{figure}

\item \textit{Wörterbuch AFINN:} Die Funktion \textit{afinn$\_$score$\_$wert} bildet den Mittelwert pro Woche und Monat.
 \begin{figure}[H]
\centering
 	\includegraphics[width=1\textwidth]{Pictures/afinn_mittelwert.png}
 	\caption{Sentimentindex auf Tweetebene}
\end{figure}
\end{itemize}

\end{appendix}

\input{Literratur}






